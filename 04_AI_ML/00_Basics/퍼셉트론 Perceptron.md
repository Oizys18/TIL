# 퍼셉트론 Perceptron

- 다수의 Input을 입력받아서 하나의 Output을 출력 
- 각각의 신호 별로 중요도에 따라 Weight을 부여하고, 신호의 총합이 정해진 임계값 세타를 넘었을 때 1을 출력한다.
- 기계학습은 weight을 정한다. 즉 wegith을 만들어내는 것이 학습이다.
-  출력값Output은 1 또는 0 이기 때문에 선형분류(Linear Classifier)모형이라고 볼 수 있다.

## 학습방법

- 초기엔 임의 설정한 weight으로 시작한다.
- 학습 데이터를 퍼셉트론 모형에 입력하며 분류가 잘못되면 weight을 개선해 나간다. ( == 학습)
- Perceptron Learning Algorithm(PLA)는 모든 학습 데이터를 정확히 분류시킬 때까지 학습이 진행된다.
- 학습데이터가 선형적으로 분리될 수 있을 때 적합한 알고리즘이다.

## 가중치와 편향

```
편향은 θ(theta)로 학습 데이터(Input)이 가중치와 계산되어 넘어야 하는 임계점으로 이 값이 높으면 높을 수록 그만큼 분류의 기준이 엄격하다는 것을 의미한다. 그래서 편향이 높을 수록 모델이 간단해지는 경향이 있으며 (변수가 적고 더 일반화 되는 경우) 오히려 과소적합(underfitting)의 위험이 발생하게 된다. 반대로 편향이 낮을수록 한계점이 낮아 데이터의 허용범위가 넓어지는 만큼 학습 데이터에만 잘 들어맞는 모델이 만들어질 수 있으며 모델이 더욱 복잡해질 것이다. 허용범위가 넓어지는 만큼 필요 없는 노이즈가 포함될 가능성도 높다.

출처: https://sacko.tistory.com/10 [데이터 분석하는 문과생, 싸코]
```

- **가중치**(weight)는 입력신호가 결과 출력에 주는 영향도를 조절하는 매개변수이고, **편향**(bias)은 뉴런(또는 노드; x를 의미)이 얼마나 쉽게 **활성화**(1로 출력; activation)되느냐를 조정하는(adjust) 매개변수이다.

## 한계점

- 선형으로 분류를 할 수 있지만 XOR와 같이 선형 분류만 가능하며 비선형 분류는 불가능하다.

## 다층 퍼셉트론을 통한 한계 극복

- 단일 퍼셉트론으로는 XOR을 분류할 수 없지만, 다층 퍼셉트론을 만들면 이를 극복할 수 있습니다. 다층(multi-layer)이라는 말은 하나의 퍼셉트론에 또 다른 퍼셉트론을 덧붙인다는 의미로 볼 수 있다. 단층 퍼셉트론이 비선형 영역을 분리할 수 없다는 것이 문제이며 다층으로 할 경우 비선형으로 이를 해결할 수 있다.

  